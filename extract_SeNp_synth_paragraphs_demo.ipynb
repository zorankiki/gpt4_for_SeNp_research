{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d1c9e3-ef08-47e7-9ac3-ba93a4d7bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, environ\n",
    "from sys import path\n",
    "\n",
    "from science_parse_api.api import parse_pdf\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import ast\n",
    "import nltk\n",
    "\n",
    "import openai\n",
    "from openai.error import RateLimitError, InvalidRequestError\n",
    "import backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f20d2bf-f0c4-4e1e-8cc2-c20268c1d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = environ.get('OPEN_AI_ORG')\n",
    "openai.api_key = environ.get('OPEN_AI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09559789-eee8-4494-91ed-610b09ffdd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_paragraphs(directory = './SeNp_research_articles/'):\n",
    "    pdf_dirs = [directory]\n",
    "    pdf_files = [pdf_dirs[0]+i for i in listdir(pdf_dirs[0])]\n",
    "    \n",
    "    # sci parse host\n",
    "    host = 'http://127.0.0.1'\n",
    "    port = '8080'\n",
    "    \n",
    "    paragraphs = {}\n",
    "    for fl in pdf_files:\n",
    "        pth = Path('./', fl).resolve()\n",
    "        parsed = parse_pdf(host, pth, port=port)\n",
    "        paragraphs[fl]=parsed\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['file'] = paragraphs.keys()\n",
    "    df['content'] = paragraphs.values() \n",
    "    df['id'] = df.content.map(lambda x: x.get('id'))\n",
    "    df['title'] = df.content.map(lambda x: x.get('title'))\n",
    "    df['abstractText'] = df.content.map(lambda x: x.get('abstractText'))\n",
    "    df['year'] = df.content.map(lambda x: x.get('year'))\n",
    "    df['authors'] = df.content.map(lambda x: x.get('authors'))\n",
    "    df['references'] = df.content.map(lambda x: x.get('references'))\n",
    "    df['sections'] = df.content.map(lambda x: x.get('sections'))\n",
    "\n",
    "    df_paragraphs = df[['file', 'id', 'title', 'year', 'authors', 'sections']].copy()\\\n",
    "    .explode('sections').reset_index(drop=True)\n",
    "\n",
    "    df_paragraphs = df_paragraphs[df_paragraphs['sections'].map(lambda x: len(x.get('text'))>0)].copy()\n",
    "\n",
    "    df_paragraphs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return(df_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4557302-96ae-4aa0-8851-fcc86a8db8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, RateLimitError)\n",
    "def text_cleaning(text, model=\"gpt-4-turbo-preview\"):\n",
    "    # print(len(text.split(' ')))\n",
    "    messages = []\n",
    "    \n",
    "    messages.append({\"role\": \"system\", \"content\":'''# who you are: you are helpful assistant, expert in biochemistry.\n",
    "    # your task: remove artefacts from not so good parsed scientific text sections.\n",
    "    # you will take input in format: section text\n",
    "    # you will respond: section text cleaned from artefacts'''})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(model=model, messages=messages, max_tokens=4095, temperature=1)\n",
    "    except InvalidRequestError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "\n",
    "    # Print the response and add it to the messages list\n",
    "    chat_message = response['choices'][0]['message']['content']\n",
    "    # print(len(chat_message.split(' ')))\n",
    "    # print(f\"Bot: {chat_message}\")\n",
    "    # messages.append({\"role\": \"assistant\", \"content\": chat_message})\n",
    "    print('*', end = \"\")\n",
    "    return(chat_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ed388e-ba66-438a-a987-7554b23cbca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, RateLimitError)\n",
    "def label_paragraph_fourth_prompt(paragraph):\n",
    "    messages = []\n",
    "    \n",
    "    messages.append({\"role\": \"system\", \"content\":'''# who you are: you are helpful assistant, expert in chemistry.\n",
    "    # your task: label paragraph that describes exact synthesis recipe for synthesis of Se nanoparticles with labels \"YES\" or \"NO\".\n",
    "    # hint: paragraph usually contains parameters such as mass of substances used, concentrations of solutions, reaction temperatures, etc. \n",
    "    # you will take input in format: #####<paragraph>#####\n",
    "    # you will respond: <label>'''})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": '#####'+paragraph+'#####'})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(model=\"gpt-4-turbo-preview\", \n",
    "                                            messages=messages, max_tokens=4095, temperature=1)\n",
    "\n",
    "    # Print the response and add it to the messages list\n",
    "    chat_message = response['choices'][0]['message']['content']\n",
    "    # print(f\"Bot: {chat_message}\")\n",
    "    # messages.append({\"role\": \"assistant\", \"content\": chat_message})\n",
    "    print(chat_message, end = \"\")\n",
    "    return(chat_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228974ae-ad9e-456d-9315-67461bd15893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs = parse_paragraphs(directory='./SeNp_research_articles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da789eb2-a316-400a-8f9b-8184723a0a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs = \\\n",
    "df_paragraphs[df_paragraphs['sections'].map(lambda x: len(x.get('text').split(' ')))>30].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3254cd-809d-4798-85f4-43fd0bf52631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************************************************************"
     ]
    }
   ],
   "source": [
    "df_paragraphs['section_text_cleaned'] = \\\n",
    "df_paragraphs['sections'].map(lambda x: text_cleaning(text = x.get('text'), model = 'gpt-3.5-turbo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd47d9b2-b18b-42ae-a7d6-0bd18b43b750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Colloids and Surfaces B: Biointerfaces 132 (20...\n",
       "2      Department of Biotechnology, University of Ver...\n",
       "3      Biogenic metal/metalloid nanoparticles of micr...\n",
       "4      Selenium nanoparticles (SeNPs) of 10â€“400 nm in...\n",
       "5      Biosynthesis of SeNPs by bacterial strains\\nFi...\n",
       "                             ...                        \n",
       "135    The release of versatile drugs from PCL micros...\n",
       "136    The release of SeNP from PCL was measured in i...\n",
       "137    Although selenium nanoparticles (SeNPs) are no...\n",
       "138    From the application aspect, degradation of bi...\n",
       "139    This study was supported by the Ministry of Ed...\n",
       "Name: section_text_cleaned, Length: 125, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragraphs['section_text_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a9acf6-d005-4cd6-9e18-c9a2edc11940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NONONONONONONOYESNONONONONONONOYESNONONONONONOYESNONOYESNONONONONONONOYESNONONONONONONONONONONONONONONONONONONONONONONONONONOYESYESNONONONONOYESNONONONONONONONONONONONONOYESNONONOYESNONONONONOYESNOYESNONONONONONOYESNONONONONONONONONONONOYESNONONONONONONONONONONONO"
     ]
    }
   ],
   "source": [
    "df_paragraphs['label_raw'] = df_paragraphs['sections'].map(lambda x: x.get('text'))\\\n",
    ".map(lambda x: label_paragraph_fourth_prompt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1e9191-b269-4a85-a1be-e2728ae0491d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YESNONONONONONOYESNONONONONONONOYESNONONONONONOYESNONOYESNONONONONONONOYESNONONONONONONONONONONONONONONONONONONONONONONONONONOYESYESNONONONONOYESNONONONONONONONONONONONONOYESNONONOYESNONONONONONONOYESNONONONONONOYESNONONONONONONONONONONONONONONONONONONONONONONONO"
     ]
    }
   ],
   "source": [
    "df_paragraphs['label_cleaned'] = df_paragraphs['section_text_cleaned'].map(lambda x: x)\\\n",
    ".map(lambda x: label_paragraph_fourth_prompt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a47ef588-8f93-413a-8ced-6e0ddd0dbe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Labeled praghraphs\n",
    "\n",
    "# for i in df_paragraphs[df_paragraphs['label_raw'] == 'YES'].sample(frac=.1)\\\n",
    "# ['sections'].map(lambda x: x.get('text')).tolist():\n",
    "#     print(i)\n",
    "#     print('**********************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30465548-be05-4616-af7b-6544e38911df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs.to_pickle(path = 'SeNp_synth_paragraphs_labeled.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310-openAI",
   "language": "python",
   "name": "p310-openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
